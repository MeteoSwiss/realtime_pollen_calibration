{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbdccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfgrib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import psyplot.project as psy\n",
    "from scipy.interpolate import griddata\n",
    "import scipy.interpolate as interp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import iconarray\n",
    "import psyplot.project as psy\n",
    "import scipy.interpolate as interp  # type: ignore\n",
    "\n",
    "from realtime_pollen_calibration import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#\n",
    "#        UTILITY FUNCTIONS\n",
    "#\n",
    "#####################################################\n",
    "\n",
    "def read_atab(file_data, file_data_mod):   \n",
    "    with open(file_data) as f:\n",
    "        for n, line in enumerate(f):\n",
    "            if line.strip()[0:8] == 'Latitude':\n",
    "                lat_stns = np.fromstring(line.strip()[10:], sep=' ')\n",
    "            if line.strip()[0:9] == 'Longitude':\n",
    "                lon_stns = np.fromstring(line.strip()[11:], sep=' ')\n",
    "            if line.strip()[0:18] == 'Missing_value_code':\n",
    "                missing_value = float(line.strip()[20:])\n",
    "            if line.strip()[0:9] == 'Indicator':\n",
    "                stn_indicators = np.array(line.strip()[11:].split('\\t'))\n",
    "            if n == 16:\n",
    "                break\n",
    "    with open(file_data_mod) as f:\n",
    "        for n, line in enumerate(f):\n",
    "            if line.strip()[0:9] == 'Indicator':\n",
    "                stn_indicators_mod = np.array(line.strip()[29:].split('         '))\n",
    "                break\n",
    "    [_, is1, is2] = np.intersect1d(stn_indicators, stn_indicators_mod, assume_unique=True, return_indices=True)\n",
    "    istation_mod = is2[np.argsort(is1)]\n",
    "    data = pd.read_csv(file_data, \\\n",
    "                       header = 17, \\\n",
    "                       delim_whitespace=True,\\\n",
    "                      parse_dates = [[1,2,3,4,5]])\n",
    "\n",
    "    data_mod = pd.read_csv(file_data_mod, \\\n",
    "                       header = 18, \\\n",
    "                       delim_whitespace=True,\\\n",
    "                      parse_dates = [[3,4,5,6,7]])\n",
    "    return data, data_mod, lat_stns, lon_stns, missing_value, istation_mod\n",
    "\n",
    "def treat_missing(array, missing_value = -9999.0, tune_pol_default = 1., verbose = False):\n",
    "    array_missing = array == missing_value\n",
    "    skip_missing = np.count_nonzero(array_missing)\n",
    "    Nstations = array.shape[1]\n",
    "    if skip_missing > 0:\n",
    "        for istation in range(Nstations):\n",
    "            if np.count_nonzero(np.abs(array[:,istation] - missing_value) < 0.01)/len(array[:,istation]) < 0.1:\n",
    "                idx1 = np.where(np.abs(array[:,istation] - missing_value) > 0.01)\n",
    "                idx2 = np.where(np.abs(array[:,istation] - missing_value) < 0.01)\n",
    "                if verbose:\n",
    "                    print(f'Less than 10% of the data is missing, \\\n",
    "                    mean of the rest is: {np.mean(array[idx1, istation])}')\n",
    "                array[idx2, istation] = np.mean(array[idx1, istation])\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('More than 10% of the data is missing')\n",
    "                array[:,istation] = tune_pol_default\n",
    "    return array\n",
    "\n",
    "def get_change_tune(\n",
    "    pollen,\n",
    "    array,\n",
    "    array_mod,\n",
    "    ds,\n",
    "    lat_stns,\n",
    "    lon_stns,\n",
    "    istation_mod,\n",
    "    tune_pol_default=1.0,\n",
    "    eps=1e-2,\n",
    "):\n",
    "    nstns = array.shape[1]\n",
    "    change_tune = np.ones(nstns)\n",
    "    for istation in range(nstns):\n",
    "        # sum of hourly observed concentrations of the last 5 days\n",
    "        sum_obs = np.sum(array[:, istation])\n",
    "        # sum of hourly modelled concentrations of the last 5 days\n",
    "        sum_mod = np.sum(array_mod[:, istation_mod])\n",
    "        # tuning factor at the current station\n",
    "        tune_stns = get_field_at(\n",
    "            ds,\n",
    "            pollen + \"tune\",\n",
    "            lat_stns[istation],\n",
    "            lon_stns[istation],\n",
    "            eps,\n",
    "        )\n",
    "        # saison days at the current station\n",
    "        # if > 0 then the pollen season has started\n",
    "        saisn_stns = get_field_at(\n",
    "            ds,\n",
    "            pollen + \"saisn\",\n",
    "            lat_stns[istation],\n",
    "            lon_stns[istation],\n",
    "            eps,\n",
    "        )\n",
    "        if (saisn_stns > 0) and ((sum_obs <= 720) or (sum_mod <= 720)):\n",
    "            change_tune[istation] = (tune_pol_default / tune_stns) ** (1 / 24)\n",
    "        elif (saisn_stns > 0) and (sum_obs > 720) and (sum_mod > 720):\n",
    "            change_tune[istation] = (sum_obs / sum_mod) ** (1 / 24)\n",
    "    return change_tune\n",
    "\n",
    "def interpolate(change, ds, field, lat_stns, lon_stns, method=\"multiply\", ipollen=0):\n",
    "    nstns = len(lat_stns)\n",
    "    if method == \"multiply\":\n",
    "        min_param = [3.389, 4.046, 7.738, 1.875]\n",
    "        max_param = [0.235, 0.222, 0.216, 0.405]\n",
    "    else:\n",
    "        min_param = 1e10 * np.ones(4)\n",
    "        max_param = -1e10 * np.ones(4)\n",
    "    diff_lon = np.zeros((nstns,) + ds.longitude.shape)\n",
    "    diff_lat = np.zeros((nstns,) + ds.longitude.shape)\n",
    "    dist = np.zeros((nstns,) + ds.longitude.shape)\n",
    "    for istation in range(nstns):\n",
    "        diff_lon[istation, :] = (\n",
    "            (ds.longitude - lon_stns[istation])\n",
    "            * np.pi\n",
    "            / 180\n",
    "            * np.cos(ds.latitude * np.pi / 180)\n",
    "        )\n",
    "        diff_lat[istation, :] = (ds.latitude - lat_stns[istation]) * np.pi / 180\n",
    "        dist[istation, :] = np.sqrt(\n",
    "            diff_lon[istation, :] ** 2 + diff_lat[istation, :] ** 2\n",
    "        )\n",
    "    if method == \"multiply\":\n",
    "        vec = np.maximum(\n",
    "            np.minimum(\n",
    "                ds[field].values\n",
    "                * np.sum(change[:, np.newaxis, np.newaxis] / dist, axis=0)\n",
    "                / np.sum(1 / dist, axis=0),\n",
    "                min_param[ipollen],\n",
    "            ),\n",
    "            max_param[ipollen],\n",
    "        )\n",
    "    elif method == \"sum\":\n",
    "        vec = np.maximum(\n",
    "            np.minimum(\n",
    "                ds[field].values\n",
    "                + np.sum(change[:, np.newaxis, np.newaxis] / dist, axis=0)\n",
    "                / np.sum(1 / dist, axis=0),\n",
    "                min_param[ipollen],\n",
    "            ),\n",
    "            max_param[ipollen],\n",
    "        )\n",
    "    return vec\n",
    "\n",
    "def plot_tunevec(ds, field, vec, lat_stns, lon_stns, filename = '', mode = 0):\n",
    "    ds['vec'] = ds[field].copy(deep=True)\n",
    "    ds.vec.values = vec\n",
    "    \n",
    "    # auxiliary plotting variables\n",
    "    lonmin = np.amin(ds.longitude)\n",
    "    lonmax = np.amax(ds.longitude)\n",
    "    latmin = np.amin(ds.latitude)\n",
    "    latmax = np.amax(ds.latitude)\n",
    "    if mode == 1:\n",
    "        MIN = 0.8#np.amin(vec)\n",
    "        MAX = 1.2#np.amax(vec)\n",
    "    elif mode == 0:\n",
    "        MIN = np.amin(vec)\n",
    "        MAX = np.amax(vec)\n",
    "    elif mode ==2:\n",
    "        MIN = -np.amax(np.abs(vec))\n",
    "        MAX = np.amax(np.abs(vec))\n",
    "    plot1 = ds.psy.plot.mapplot(\n",
    "    name=\"vec\",\n",
    "    title=\"Alder Tuning Factor \",\n",
    "    titlesize=15,\n",
    "    map_extent = [lonmin, lonmax, latmin, latmax],\n",
    "    bounds = {'method': 'minmax', 'N':100, 'vmin': MIN, 'vmax': MAX},\n",
    "    cticks=np.linspace(MIN,MAX,6),\n",
    "    lakes=True,\n",
    "    borders=True,\n",
    "    rivers=True,\n",
    "    cticksize=8,\n",
    "    clabel=\"Tuning Factor []\",\n",
    "    grid_labelsize=8,\n",
    "    projection='robin',\n",
    "    cmap='RdBu_r', xgrid = False, ygrid = False)\n",
    "    fig = plt.gcf()\n",
    "    Nstations = lon_stns.shape[0]\n",
    "    pos_lon = np.zeros(Nstations)\n",
    "    pos_lat = np.zeros(Nstations)\n",
    "    vec_stns = np.zeros(Nstations)\n",
    "    eps = 1e-2\n",
    "    for istation in range(Nstations):\n",
    "        pos_lon[istation],pos_lat[istation] = iconarray.add_coordinates(lon_stns[istation],lat_stns[istation],lonmin,lonmax,latmin,latmax)\n",
    "        vec_stns[istation] = get_field_at(ds, 'vec', lat_stns[istation], lon_stns[istation])\n",
    "    #fig.axes[0].scatter(pos_lon, pos_lat,s=20,color='w',marker='o', transform=fig.axes[0].transAxes) \n",
    "    fig.axes[0].scatter(pos_lon, pos_lat,s=50,color='k',marker='o', transform=fig.axes[0].transAxes) \n",
    "    fig.axes[0].scatter(pos_lon, pos_lat,s=20,c=vec_stns, marker='o', alpha=1, \n",
    "                        transform=fig.axes[0].transAxes, vmin=MIN, vmax = MAX, cmap = 'RdBu_r') \n",
    "    if len(filename) > 0:\n",
    "        output_file = '/store/s83/gvanpary/Figures/' + filename\n",
    "        plt.savefig(output_file)\n",
    "    plot1.show()\n",
    "    \n",
    "def test_change_tune(pollen, change_tune, ds, ds2, lat_stns, lon_stns, eps = 1e-2):\n",
    "    Nstations = len(lon_stns)\n",
    "    tune_OLD = np.zeros(Nstations)\n",
    "    tune_next = np.zeros(Nstations)\n",
    "    for istation in range(Nstations):\n",
    "        tune_OLD[istation] = get_field_at(ds, pollen + 'tune', lat_stns[istation], lon_stns[istation])\n",
    "        tune_next[istation] = get_field_at(ds2, pollen + 'tune', lat_stns[istation], lon_stns[istation])\n",
    "    change_tune_2 = tune_next/tune_OLD\n",
    "    Err = change_tune_2 - change_tune\n",
    "    return Err\n",
    "'''\n",
    "    Set change_tune to be coherent with the next timestep output\n",
    "    in order to test the interpolation\n",
    "    note that for this computation there are some approximations, i.e.\n",
    "    AT one station 1/d_station >> 1/d_other_station and thus all the other\n",
    "    terms in the interpolation are neglected.\n",
    "'''\n",
    "def test_interpolation(ds, ds2, lat_stns, lon_stns, eps = 1e-2):\n",
    "    Nstations = len(lon_stns)\n",
    "    tune_OLD = np.zeros(Nstations)\n",
    "    tune_next = np.zeros(Nstations)\n",
    "    for istation in range(Nstations):\n",
    "        tune_OLD[istation] = ds.ALNUtune.where((np.abs(ds.longitude-lon_stns[istation]) < eps)\\\n",
    "                                & (np.abs(ds.latitude-lat_stns[istation]) < eps), drop=True).values[0][0]\n",
    "        tune_next[istation] = ds2.ALNUtune.where((np.abs(ds2.longitude-lon_stns[istation]) < eps)\\\n",
    "                                & (np.abs(ds2.latitude-lat_stns[istation]) < eps), drop=True).values[0][0]\n",
    "    change_tune_2 = tune_next/tune_OLD\n",
    "    tune_vec_2 = interpolate(change_tune_2, ds, 'ALNUtune', lat_stns, lon_stns, 'mult')\n",
    "    Err = ds2.ALNUtune - tune_vec_2\n",
    "    return Err, change_tune_2, tune_vec_2\n",
    "\n",
    "def get_field_at(ds, field, lat, lon, eps = 1e-2):\n",
    "    dist = (ds.latitude - lat)**2 + (ds.longitude - lon)**2\n",
    "    return ds[field].where(dist == dist.min(), drop = True)\n",
    "#    return ds[field].where((np.abs(ds.longitude-lon) < eps)\\\n",
    "#                    & (np.abs(ds.latitude-lat) < eps), drop=True).values[0][0]\n",
    "\n",
    "def interpolate2(change_tune, ds, lat_stns, lon_stns, epsilon = 100):\n",
    "    nstns = len(lat_stns)\n",
    "    stns_points = np.array([[lat_stns[i], lon_stns[i]] for i in range(nstns)])*np.pi/180\n",
    "    grid_points = np.array(\n",
    "        [ds.latitude.values.flatten(), ds.longitude.values.flatten()]\n",
    "    ).T*np.pi/180\n",
    "    change_tune_vec = interp.RBFInterpolator(\n",
    "        stns_points, change_tune-1, kernel=\"gaussian\", epsilon=epsilon, degree = -1, smoothing = 0,\n",
    "    )(grid_points).reshape(ds.latitude.values.shape) + 1\n",
    "    return change_tune_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca755a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# debugging checks\n",
    "\n",
    "# first check if get_change_tune is coherent with the next timestep output\n",
    "istation = 2\n",
    "print(f'Checking station n°{istation}')\n",
    "eps = 1e-2\n",
    "tune_OLD = ds.ALNUtune.where((np.abs(ds.longitude-lon_stns[istation]) < eps)\\\n",
    "                        & (np.abs(ds.latitude-lat_stns[istation]) < eps), drop=True).values[0][0]\n",
    "\n",
    "print(f'Its old tune value was {tune_OLD}')\n",
    "tune_NEW = ds.tune_vec.where((np.abs(ds.longitude-lon_stns[istation]) < eps)\\\n",
    "                        & (np.abs(ds.latitude-lat_stns[istation]) < eps), drop=True).values[0][0]\n",
    "\n",
    "print(f'Its new tune value is {tune_NEW}')\n",
    "print(f'The corresponding change_tune value is {change_tune[istation]}, \\\n",
    "(IF#1: {1/tune_OLD**(1/24)}, IF#2: {((np.sum(array[:,istation]) / np.sum(array_mod[:,istation_mod[istation]]))**(1/24))})')\n",
    "print(f'Condition #1 would yield: {tune_OLD**(23/24)}')\n",
    "print(f'Condition #2 would yield: {tune_OLD*((np.sum(array[:,istation]) / np.sum(array_mod[:,istation_mod[istation]]))**(1/24))}')\n",
    "tune_next = ds2.ALNUtune.where((np.abs(ds.longitude-lon_stns[istation]) < eps)\\\n",
    "                        & (np.abs(ds.latitude-lat_stns[istation]) < eps), drop=True).values[0][0]\n",
    "print(f'The new tune value should be according to the next timestep field {tune_next}')\n",
    "print(f'And the corrresponding change_tune should be: {tune_next/tune_OLD}')\n",
    "print('---------------------')\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b13183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests\n",
    "\n",
    "Err, change_tune_2, tune_vec_2 = test_interpolation(ds, ds2, lat_stns, lon_stns, eps = 1e-2)\n",
    "#Err2 = test_change_tune(change_tune, ds, ds2, lat_stns, lon_stns, eps = 1e-2)\n",
    "\n",
    "dtimesteps = ds.ALNUtune - ds2.ALNUtune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Err = np.abs(Err)\n",
    "ds['err'] = ds.ALNUtune.copy(deep=True)\n",
    "ds.err.values = Err\n",
    "\n",
    "# auxiliary plotting variables\n",
    "lonmin = np.amin(ds.longitude)\n",
    "lonmax = np.amax(ds.longitude)\n",
    "latmin = np.amin(ds.latitude)\n",
    "latmax = np.amax(ds.latitude)\n",
    "\n",
    "MIN = np.amin(Err)\n",
    "MAX = np.amax(Err)\n",
    "plot1 = ds.psy.plot.mapplot(\n",
    "name=\"err\",\n",
    "title=\"Residual error (ALNU tune field)\",\n",
    "map_extent = [lonmin, lonmax, latmin, latmax],\n",
    "bounds = {'method': 'minmax', 'N':100, 'vmin': MIN, 'vmax': MAX},\n",
    "cticks=np.linspace(MIN,MAX,6),\n",
    "lakes=True,\n",
    "borders=True,\n",
    "rivers=True,\n",
    "cticksize=8,\n",
    "clabel=\"Tuning Factor []\",\n",
    "grid_labelsize=8,\n",
    "projection='robin',\n",
    "cmap='RdBu_r', xgrid = False, ygrid = False)\n",
    "fig = plt.gcf()\n",
    "Nstations = lon_stns.shape[0]\n",
    "pos_lon = np.zeros(Nstations)\n",
    "pos_lat = np.zeros(Nstations)\n",
    "vec_stns = np.zeros(Nstations)\n",
    "eps = 1e-2\n",
    "for istation in range(Nstations):\n",
    "    pos_lon[istation],pos_lat[istation] = iconarray.add_coordinates(lon_stns[istation],lat_stns[istation],lonmin,lonmax,latmin,latmax)\n",
    "    vec_stns[istation] = ds.err.where((np.abs(ds.longitude-lon_stns[istation]) < eps)\\\n",
    "                    & (np.abs(ds.latitude-lat_stns[istation]) < eps), drop=True).values[0][0]\n",
    "fig.axes[0].scatter(pos_lon, pos_lat,s=20,color='w',marker='o', transform=fig.axes[0].transAxes) \n",
    "fig.axes[0].scatter(pos_lon, pos_lat,s=10,color='k',marker='o', transform=fig.axes[0].transAxes) \n",
    "fig.axes[0].scatter(pos_lon, pos_lat,s=15,c=vec_stns,marker='o', alpha=0, transform=fig.axes[0].transAxes, vmin=MIN, vmax = MAX, cmap = 'RdBu_r') \n",
    "\n",
    "output_file = '/store/s83/gvanpary/Figures/' + 'interpolation_residual'\n",
    "plt.savefig(output_file)\n",
    "plot1.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533f3a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "    Reproduction of subroutine update_strength_realtime\n",
    "    from the COSMO code.\n",
    "        Inputs: \n",
    "        Outputs:\n",
    "        Steps: 1) [x] Load data from stations and from the model \n",
    "               2) [x] Treat missing data from stations \n",
    "               3) [x] Find cell indices of stations from lat-lon info\n",
    "               4) [x] Modify tune_vec according to stations info\n",
    "               5) [x] Interpolate over all grid cells\n",
    "        TODO:  [x] Treat missing data from stations\n",
    "               [x] INTERPOLATION: Implement IDW as is done in COSMO for different pollen types\n",
    "               [x] Put everything as functions\n",
    "               [x] Create python script in src/\n",
    "               [ ] x Do writing in GRIB file -> commit\n",
    "               [x] Implement the other FORTRAN function and adapt the common functions\n",
    "               [x] check with 1 hr later output\n",
    "               [x] check if tune_vec is not also used as input in interpolation\n",
    "                \n",
    "               \n",
    "               [ ] Adapt Input management to other cases than ALNU/ICON input\n",
    "               [ ] test on ICON input with every pollen type\n",
    "'''\n",
    "\n",
    "file_data = '/scratch/gvanpary/pollen/data/atabs/alnu_pollen_measured_values_2022020805.atab'\n",
    "file_data_mod = '/scratch/gvanpary/pollen/data/atabs/alnu_pollen_modelled_values_2022022207.atab'\n",
    "\n",
    "data, data_mod, lat_stns, lon_stns, missing_value, istation_mod = read_atab(file_data, file_data_mod)\n",
    "\n",
    "pollen_types = ['ALNU', 'BETU', 'POAC', 'CORY']\n",
    "ipollen = 0\n",
    "array = data[data['PARAMETER'] == pollen_types[ipollen]].iloc[:,2:].to_numpy()\n",
    "array_mod = data_mod[data_mod['PARAMETER'] == pollen_types[ipollen]].iloc[:,2:].to_numpy()\n",
    "\n",
    "'''\n",
    "    READING DATA FROM GRIB FILE\n",
    "'''\n",
    "\n",
    "ds = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/grib2_files_cosmo1e/laf2022022207_ALNUtune',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "ds2 = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/grib2_files_cosmo1e/laf2022022208_ALNUtune',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "array = treat_missing(array, missing_value, verbose = True)\n",
    "change_tune = get_change_tune(pollen_types[ipollen], array, array_mod, ds, lat_stns, lon_stns, istation_mod)\n",
    "change_tune_vec = interpolate2(change_tune, ds, lat_stns, lon_stns)\n",
    "tune_vec_OLD = interpolate(change_tune, ds, 'ALNUtune', lat_stns, lon_stns, method= 'multiply', ipollen = 0)\n",
    "\n",
    "Nstations = len(lon_stns)\n",
    "tune_OLD = np.zeros(Nstations)\n",
    "tune_next = np.zeros(Nstations)\n",
    "for istation in range(Nstations):\n",
    "    tune_OLD[istation] = get_field_at(ds, 'ALNUtune', lat_stns[istation], lon_stns[istation])\n",
    "    tune_next[istation] = get_field_at(ds2,'ALNUtune', lat_stns[istation], lon_stns[istation])\n",
    "change_tune_2 = tune_next/tune_OLD\n",
    "change_tune_vec_2 = interpolate2(change_tune_2, ds, lat_stns, lon_stns)\n",
    "tune_vec_OLD_2 = interpolate(change_tune_2, ds, 'ALNUtune', lat_stns, lon_stns, method= 'multiply', ipollen = 0)\n",
    "#plot_tunevec(ds, 'ALNUtune', change_tune_vec, lat_stns, lon_stns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edb8f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(change_tune, 'o')\n",
    "plt.plot(change_tune_2, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c2ad8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# T - T+1\n",
    "\n",
    "plot_tunevec(ds, 'ALNUtune', ds.ALNUtune - ds2.ALNUtune, lat_stns, lon_stns, mode =2)\n",
    "\n",
    "# gauss interp - T+1 \n",
    "\n",
    "plot_tunevec(ds, 'ALNUtune', change_tune_vec*ds.ALNUtune - ds2.ALNUtune, lat_stns, lon_stns, mode =2)\n",
    "\n",
    "# cosmo interp - T+1 \n",
    "plot_tunevec(ds, 'ALNUtune', tune_vec_OLD - ds2.ALNUtune, lat_stns, lon_stns, mode =2)\n",
    "\n",
    "# gauss interp (change_tune from T+1/T) - T+1\n",
    "plot_tunevec(ds, 'ALNUtune', change_tune_vec_2*ds.ALNUtune - ds2.ALNUtune, lat_stns, lon_stns, mode =2)\n",
    "\n",
    "# cosmo interp (change_tune from T+1/T) - T+1\n",
    "plot_tunevec(ds, 'ALNUtune', tune_vec_OLD_2 - ds2.ALNUtune, lat_stns, lon_stns, mode =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9512b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_field_at(ds, 'vec', lat_stns[0], lon_stns[0])*get_field_at(ds, 'ALNUtune', lat_stns[0], lon_stns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357838fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_field_at(ds, 'ALNUtune', lat_stns[0], lon_stns[0])*change_tune[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b29826",
   "metadata": {},
   "outputs": [],
   "source": [
    "Err = test_change_tune('ALNU', change_tune, ds, ds2, lat_stns, lon_stns, eps = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa436cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "change_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655729f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test other inputs\n",
    "# BETU test case\n",
    "file_data = '/scratch/gvanpary/pollen/data/atabs/betu_pollen_measured_values_2022032309.atab'\n",
    "file_data_mod = '/scratch/gvanpary/pollen/data/atabs/betu_pollen_modelled_values_2022032309.atab'\n",
    "data, data_mod, lat_stns, lon_stns, missing_value, istation_mod = read_atab(file_data, file_data_mod)\n",
    "pollen_types = ['ALNU', 'BETU', 'POAC', 'CORY']\n",
    "ipollen = 1\n",
    "array = data[data['PARAMETER'] == pollen_types[ipollen]].iloc[:,2:].to_numpy()\n",
    "array_mod = data_mod[data_mod['PARAMETER'] == pollen_types[ipollen]].iloc[:,2:].to_numpy()\n",
    "ds = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/grib2_files_cosmo1e/laf2022032309_BETUtune',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "ds2 = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/grib2_files_cosmo1e/laf2022032310_BETUtune',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "\n",
    "array = treat_missing(array, missing_value, verbose = True)\n",
    "change_tune = get_change_tune(pollen_types[ipollen], array, array_mod, ds, lat_stns, lon_stns, istation_mod)\n",
    "tune_vec = interpolate2(change_tune, ds, lat_stns, lon_stns)\n",
    "plot_tunevec(ds, 'BETUtune', change_tune, tune_vec, lat_stns, lon_stns, delta_tune= True)\n",
    "Err = test_change_tune('BETU', change_tune, ds, ds2, lat_stns, lon_stns, eps = 1e-2)\n",
    "print(Err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649bd3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test other inputs\n",
    "# CORY test case\n",
    "file_data = '/scratch/gvanpary/pollen/data/atabs/cory_pollen_measured_values_2022021110.atab'\n",
    "file_data_mod = '/scratch/gvanpary/pollen/data/atabs/cory_pollen_modelled_values_2022021110.atab'\n",
    "data, data_mod, lat_stns, lon_stns, missing_value, istation_mod = read_atab(file_data, file_data_mod)\n",
    "pollen_types = ['ALNU', 'BETU', 'POAC', 'CORY']\n",
    "ipollen = 3\n",
    "array = data[data['PARAMETER'] == pollen_types[ipollen]].iloc[:,2:].to_numpy()\n",
    "array_mod = data_mod[data_mod['PARAMETER'] == pollen_types[ipollen]].iloc[:,2:].to_numpy()\n",
    "ds = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/grib2_files_cosmo1e/laf2022021110_CORYtune',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "ds2 = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/grib2_files_cosmo1e/laf2022021111_CORYtune',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "\n",
    "array = treat_missing(array, missing_value, verbose = True)\n",
    "change_tune = get_change_tune(pollen_types[ipollen], array, array_mod, ds, lat_stns, lon_stns, istation_mod)\n",
    "#tune_vec = interpolate2(change_tune, ds, lat_stns, lon_stns)\n",
    "#plot_tunevec(ds, 'CORYtune', change_tune, tune_vec, lat_stns, lon_stns, delta_tune= True)\n",
    "#Err = test_change_tune('CORY', change_tune, ds, ds2, lat_stns, lon_stns, eps = 1e-2)\n",
    "#print(Err)\n",
    "\n",
    "tune_vec = interpolate(change_tune, ds, 'CORYtune', lat_stns, lon_stns, method= 'mult', ipollen=ipollen)\n",
    "Err = tune_vec - ds2.CORYtune\n",
    "plot_tunevec(ds, 'CORYtune', tune_vec, tune_vec, lat_stns, lon_stns)\n",
    "plot_tunevec(ds2, 'CORYtune', ds2.CORYtune, tune_vec, lat_stns, lon_stns)\n",
    "plot_tunevec(ds2, 'CORYtune', Err, tune_vec, lat_stns, lon_stns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Err.values.flatten()[0:-1:500], '.')\n",
    "#plt.plot((ds.CORYtune - ds2.CORYtune).values.flatten()[0:-1:500], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7cd87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check uncertainty linked to the station position\n",
    "# CORY test case\n",
    "file_data = '/scratch/gvanpary/pollen/data/atabs/cory_pollen_measured_values_2022021110.atab'\n",
    "file_data_mod = '/scratch/gvanpary/pollen/data/atabs/cory_pollen_modelled_values_2022021110.atab'\n",
    "data, data_mod, lat_stns, lon_stns, missing_value, istation_mod = read_atab(file_data, file_data_mod)\n",
    "pollen_types = ['ALNU', 'BETU', 'POAC', 'CORY']\n",
    "ipollen = 3\n",
    "array = data[data['PARAMETER'] == pollen_types[ipollen]].iloc[:,2:].to_numpy()\n",
    "array_mod = data_mod[data_mod['PARAMETER'] == pollen_types[ipollen]].iloc[:,2:].to_numpy()\n",
    "ds = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/grib2_files_cosmo1e/laf2022021110_CORYtune',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "ds2 = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/grib2_files_cosmo1e/laf2022021111_CORYtune',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "\n",
    "array = treat_missing(array, missing_value, verbose = True)\n",
    "\n",
    "# now instead of getting one change tune, we get 5 (one for each neighbour cell of a 2D grid\n",
    "# here we consider the COSMO grid for this test)\n",
    "\n",
    "dlat = 1\n",
    "dlon = 1\n",
    "# first get the one as usual\n",
    "def get_field_at(ds, field, lat, lon, eps = 1e-2):\n",
    "    dist = (ds.latitude - lat)**2 + (ds.longitude - lon)**2\n",
    "    return ds[field].where(dist == dist.min(), drop = True)\n",
    "\n",
    "change_tune = get_change_tune(pollen_types[ipollen], array, array_mod, ds, lat_stns, lon_stns, istation_mod)\n",
    "\n",
    "def get_field_at(ds, field, lat, lon, eps = 1e-2):\n",
    "    dist = (ds.latitude - lat + dlat)**2 + (ds.longitude - lon)**2\n",
    "    return ds[field].where(dist == dist.min(), drop = True)\n",
    "\n",
    "change_tune_2 = get_change_tune(pollen_types[ipollen], array, array_mod, ds, lat_stns, lon_stns, istation_mod)\n",
    "\n",
    "def get_field_at(ds, field, lat, lon, eps = 1e-2):\n",
    "    dist = (ds.latitude - lat - dlat)**2 + (ds.longitude - lon)**2\n",
    "    return ds[field].where(dist == dist.min(), drop = True)\n",
    "\n",
    "change_tune_3 = get_change_tune(pollen_types[ipollen], array, array_mod, ds, lat_stns, lon_stns, istation_mod)\n",
    "\n",
    "def get_field_at(ds, field, lat, lon, eps = 1e-2):\n",
    "    dist = (ds.latitude - lat)**2 + (ds.longitude - lon + dlon)**2\n",
    "    return ds[field].where(dist == dist.min(), drop = True)\n",
    "\n",
    "change_tune_4 = get_change_tune(pollen_types[ipollen], array, array_mod, ds, lat_stns, lon_stns, istation_mod)\n",
    "\n",
    "def get_field_at(ds, field, lat, lon, eps = 1e-2):\n",
    "    dist = (ds.latitude - lat)**2 + (ds.longitude - lon - dlon)**2\n",
    "    return ds[field].where(dist == dist.min(), drop = True)\n",
    "\n",
    "change_tune_5 = get_change_tune(pollen_types[ipollen], array, array_mod, ds, lat_stns, lon_stns, istation_mod)\n",
    "\n",
    "print(change_tune)\n",
    "print(change_tune_2)\n",
    "print(change_tune_3)\n",
    "print(change_tune_4)\n",
    "print(change_tune_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed046383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds2['diffr'] = ds2.ALNUtune.copy(deep=True)\n",
    "ds2.diffr.values = ds2.ALNUtune - ds.tune_vec\n",
    "\n",
    "ds2['diff_t'] = ds2.ALNUtune.copy(deep=True)\n",
    "ds2.diff_t.values = ds2.ALNUtune - ds.ALNUtune\n",
    "\n",
    "ds2['diff_t2'] = ds2.ALNUtune.copy(deep=True)\n",
    "ds2.diff_t2.values = ds.tune_vec - ds.ALNUtune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f77402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/laf2022020805_filtered',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009823b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/laf2022020805_filtered',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "\n",
    "DATE = pd.Timestamp(ds.time.values).day_of_year + 1 + 31\n",
    "jul_days_excl = {\"ALNUctsum\": 14, \"BETUctsum\": 40, \"CORYctsum\": 3, \"POACctsum\": 46}\n",
    "jul_days_excl = [14,40,3,46]\n",
    "eps = 1e-2\n",
    "Nstations = array.shape[1]\n",
    "change_tthrs = np.zeros(Nstations)\n",
    "change_tthre = np.zeros(Nstations)\n",
    "verbose = True\n",
    "for istation in range(Nstations):\n",
    "    tthrs_stns = get_field_at(ds, pollen_types[ipollen] + 'tthrs', lon_stns[istation], lat_stns[istation], eps)\n",
    "    tthre_stns = get_field_at(ds, pollen_types[ipollen] + 'tthre', lon_stns[istation], lat_stns[istation], eps)\n",
    "    saisn_stns = get_field_at(ds, pollen_types[ipollen] + 'saisn', lon_stns[istation], lat_stns[istation], eps)\n",
    "    ctsum_stns = get_field_at(ds, pollen_types[ipollen] + 'ctsum', lon_stns[istation], lat_stns[istation], eps)\n",
    "    T_2M_stns = get_field_at(ds, 'T_2M', lon_stns[istation], lat_stns[istation], eps) - 273.15\n",
    "    sum_obs_24 = np.sum(array[96:,istation])\n",
    "    sum_obs = np.sum(array[:,istation])\n",
    "    print(f'Current station n°{istation}, last 24H obs {sum_obs_24}, and last 120H {sum_obs}')\n",
    "    print(f'Cumulative temperature sum {ctsum_stns} and threshold: {tthrs_stns}')\n",
    "    # ADJUSTMENT OF SEASON START AND END AT THE BEGINNING OF THE SEASON\n",
    "    if ((sum_obs_24 >= 240) and (sum_obs >= 720) and ctsum_stns < tthrs_stns):\n",
    "        change_tthrs[istation] = (ctsum_stns - tthrs_stns)\n",
    "        change_tthre[istation] = (ctsum_stns - tthrs_stns)\n",
    "        if verbose:\n",
    "            print(f'Big data and below threshold')\n",
    "    elif ((sum_obs_24 < 240) and (sum_obs_24 >= 0) \\\n",
    "        and (sum_obs < 720) and (sum_obs >= 0)\\\n",
    "        and (ctsum_stns > tthrs_stns) and (ctsum_stns > tthre_stns)\\\n",
    "        and (saisn_stns < 10) and (saisn_stns > 0)):\n",
    "        if verbose:\n",
    "            print(f'Low data and in first 10 days of season')\n",
    "        change_tthrs[istation] = T_2M_stns*(DATE - jul_days_excl[0])\n",
    "        change_tthre[istation] = T_2M_stns*(DATE - jul_days_excl[0])\n",
    "        \n",
    "    # ADJUSTMENT OF SEASON END AT THE END OF THE SEASON\n",
    "    if ((np.sum(array[96:,istation]) < 240) and (np.sum(array[96:,istation]) >= 0)\\\n",
    "        and (np.sum(array[:,istation]) < 720) and (np.sum(array[:,istation]) >= 0)\\\n",
    "        and (ctsum_stns + T_2M_stns*5*DATE > tthre_stns)\\\n",
    "        and (ctsum_stns < tthre_stns)):\n",
    "        change_tthre[istation] += (ctsum_stns - tthre_stns)\n",
    "        if verbose:\n",
    "            print(f'Big data and below threshold')\n",
    "    elif ((np.sum(array[96:,istation]) > 240) and (np.sum(array[:,istation]) > 720)\\\n",
    "        and (ctsum_stns + T_2M_stns*5*DATE > tthre_stns)\\\n",
    "        and (ctsum_stns < tthre_stns)):\n",
    "        change_tthre[istation] += T_2M_stns*(DATE - jul_days_excl[0])\n",
    "    # FAILSAFE \n",
    "    if (change_tthrs[istation] > 0):\n",
    "        change_tthrs[istation] = min(1000, change_tthrs[istation])\n",
    "    elif (change_tthrs[istation] <= 0):\n",
    "        change_tthrs[istation] = max(-1000, change_tthrs[istation])\n",
    "\n",
    "tthrs_vec = interpolate(change_tthrs, ds, 'ALNUtthrs', lat_stns, lon_stns, 'sum')\n",
    "tthre_vec = interpolate(change_tthre, ds, 'ALNUtthre', lat_stns, lon_stns, 'sum')\n",
    "plot_tunevec(ds, 'ALNUtthrs', change_tthrs, tthrs_vec, lon_stns, lat_stns)\n",
    "plot_tunevec(ds, 'ALNUtthre', change_tthre, tthre_vec, lon_stns, lat_stns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37b5de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds2 = cfgrib.open_dataset(\n",
    "        '/scratch/gvanpary/pollen/data/laf2022020806_filtered',\n",
    "        encode_cf=(\"time\", \"geography\", \"vertical\")\n",
    "    )\n",
    "\n",
    "ds2['diffr'] = ds2.ALNUtthrs.copy(deep=True)\n",
    "ds2.diffr.values = ds2.ALNUtthre -tthre_vec\n",
    "\n",
    "lonmin = np.amin(ds.longitude)\n",
    "lonmax = np.amax(ds.longitude)\n",
    "latmin = np.amin(ds.latitude)\n",
    "latmax = np.amax(ds.latitude)\n",
    "\n",
    "\n",
    "plot2= ds2.psy.plot.mapplot(\n",
    "name=\"diffr\",\n",
    "title=\"tthrs(t+1) - Python\",\n",
    "titlesize=15,\n",
    "map_extent = [lonmin, lonmax, latmin, latmax],\n",
    "bounds = {'method': 'minmax', 'N':100},\n",
    "lakes=True,\n",
    "borders=True,\n",
    "rivers=True,\n",
    "cticksize=8,\n",
    "clabel=\"Tuning Factor []\",\n",
    "grid_labelsize=8,\n",
    "projection='robin',\n",
    "cmap='RdBu_r', xgrid = False, ygrid = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc67b61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "change_tune_vec = interpolate2(change_tune, ds, lat_stns, lon_stns, 200)\n",
    "print(f'Max change tune at stations: {np.amax(change_tune)}')\n",
    "print(f'Min change tune at stations: {np.amin(change_tune)}')\n",
    "print(f'Max change tune extrapolation: {np.amax(change_tune_vec)}')\n",
    "print(f'Min change tune extrapolation: {np.amin(change_tune_vec)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c31ae4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_tunevec(ds, 'ALNUtune', change_tune, change_tune_vec, lat_stns, lon_stns, filename = 'delta_tune_RBF_2', delta_tune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d12bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_tunevec(ds2, 'ALNUtune', change_tune, ds2.ALNUtune, lat_stns, lon_stns)\n",
    "plot_tunevec(ds, 'ALNUtune', change_tune, change_tune_vec*ds.ALNUtune, lat_stns, lon_stns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
